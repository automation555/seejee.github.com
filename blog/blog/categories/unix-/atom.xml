<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: UNIX, | Simple is not easy.]]></title>
  <link href="http://seejee.github.com//blog/categories/unix-/atom.xml" rel="self"/>
  <link href="http://seejee.github.com//"/>
  <updated>2013-01-20T23:26:00-05:00</updated>
  <id>http://seejee.github.com//</id>
  <author>
    <name><![CDATA[Chris Geihsler]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[SRP: The Unix Way]]></title>
    <link href="http://seejee.github.com//blog/2013/01/20/srp-the-unix-way/"/>
    <updated>2013-01-20T23:17:00-05:00</updated>
    <id>http://seejee.github.com//blog/2013/01/20/srp-the-unix-way</id>
    <content type="html"><![CDATA[<p>Chaining together a set of UNIX's small, simple command line utilities gives the operator the ability to solve complex problems in a concise way. Many of these tools are over 30 years old, and yet they continue to be used to solve modern problems.</p>

<p>Specifically, this week at work we were focusing on optimizing our Rails application's database queries. We were looking for controller actions that made the same database query several times so that we could we eliminate unnecessary database I/O. The application log files contained all the data necessary to find these duplicated queries, we just needed a way to scrape the data and group it in a meaningful way.</p>

<p>We created the following set of commands:</p>

<pre><code>sed '1,/CurrentItemsController#show/d' log/test.log | \
sed '/Completed/,$d' | sed 's/^.*SELECT/SELECT/' | \
sort | uniq -c | sort -r | head -5
</code></pre>

<p>A quick explanation of each command:</p>

<ol>
<li>Read the log file and skip all the lines before the controller action.</li>
</ol>


<pre><code>sed '1,/CurrentItemsController#show/d' log/test.log
</code></pre>

<ol>
<li>Skip all the lines after the controller action.</li>
</ol>


<pre><code>sed '/Completed/,$d' 
</code></pre>

<ol>
<li>Remove all the text on each line that precedes 'SELECT'.</li>
</ol>


<pre><code>sed 's/^.*SELECT/SELECT/'
</code></pre>

<ol>
<li>Sort the rows so duplicate queries will be on adjacent lines.</li>
</ol>


<pre><code>sort
</code></pre>

<ol>
<li>Group the duplicate lines and count them.</li>
</ol>


<pre><code>uniq -c
</code></pre>

<ol>
<li>Sort the queries by how many times they were duped.</li>
</ol>


<pre><code>sort
</code></pre>

<ol>
<li>Return the top 5.</li>
</ol>


<pre><code>head -5
</code></pre>

<p>And it generated this output:</p>

<pre><code>7 SELECT COUNT(*) FROM "activity_attemptables" WHERE "activity_attemptables"."activity_id" = 1 AND "activity_attemptables"."completed" = 'f'
7 SELECT "activities".* FROM "activities" WHERE "activities"."lesson_id" = 1 AND "activities"."completed" = 'f' ORDER BY activities.position LIMIT 1
4 SELECT "lesson".* FROM "lesson" WHERE "lesson"."id" = 1 AND (lesson.passed IS NULL) ORDER BY lesson.position LIMIT 1
3 SELECT COUNT(*) FROM "activity_attemptables" WHERE "activity_attemptables"."activity_id" = 1 AND "activity_attemptables"."completed" = 'f'
3 SELECT "activities".* FROM "activities" WHERE "activities"."lesson_id" = 1 AND "activities"."completed" = 'f' ORDER BY activities.position LIMIT 1
</code></pre>

<p>Armed with the sorted list of the duplicated queries, we were able to find the sources of the duplication and optimize them.</p>

<p>While I hope you find the concrete example above to be useful, I used the example to make a larger point. Each of the utilities used above has a single responsibility. Because of this, stringing them together to work in ways the original authors never intended was relatively easy.</p>

<p>As we write software, one of the hardest things we have to do is build the right thing for today while making it easy to accommodate the needs of the future. In my experience, this kind of flexibility comes from decomposing objects and functions into small components that have a single responsibility. As requirements change, if a system is decomposed well, then only a few components will need to be added or changed to accommodate the change.</p>

<p>So, before adding new behavior to existing objects, consider this: Did the UNIX designers give grep the ability to count lines? No! They made wc. But, grep <em>was</em> modified to support different kinds of regular expressions.</p>

<p>The UNIX command line toolset is a great example of decomposition into SRP. I hope you will use it not only to solve problems directly, but also to inform your own object design so that your system will achieve some of the same flexibility as UNIX.</p>
]]></content>
  </entry>
  
</feed>
